{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aae091e5",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <u><h2>Data Analysis And Recognition</h2></u>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5d3dad",
   "metadata": {},
   "source": [
    "<u>\n",
    "<h4>Import modules</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7867b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os # To import test image files\n",
    "import cv2 # To work with opencv images\n",
    "from PIL import Image # Image submodule to work with pillow images\n",
    "import pytesseract as pt # pytesseract module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54d216f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc-text.jpg\n",
      "bound-text-1.jpg\n",
      "bound-text-2.jpg\n",
      "contact-1.jpg\n",
      "download.png\n",
      "hello-text.jpg\n",
      "hindi-news-1.jpg\n",
      "hindi-news-2.jpg\n",
      "hindi-text-1.jpg\n",
      "hindi-text-2.jpg\n",
      "image-paths.txt\n",
      "jap-text-1.png\n",
      "jap-text-2.png\n",
      "letter-1.png\n",
      "magazine-1.jpg\n",
      "news-1.png\n",
      "news-2.jpg\n",
      "portu-text-1.jpg\n",
      "portu-text-2.jpg\n",
      "project test images - Shortcut.lnk\n",
      "Screenshot 2023-02-03 121212.png\n",
      "selfie-circle.jpg\n",
      "sin-text-1.gif\n",
      "sin-text-2.gif\n",
      "span-text-1.png\n",
      "tam-text-1.png\n",
      "WhatsApp Image 2023-01-13 at 11.12.39.jpg\n"
     ]
    }
   ],
   "source": [
    "test_img_path = \"P:\\\\ML project\\\\project test images\"\n",
    "create_path = lambda f : os.path.join(test_img_path, f)\n",
    "\n",
    "test_image_files = os.listdir(test_img_path)\n",
    "\n",
    "for f in test_image_files:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27e88dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(img_path, size=(500, 500)):\n",
    "    image = cv2.imread(img_path)\n",
    "    image = cv2.resize(image, size)\n",
    "    \n",
    "    cv2.imshow(\"IMAGE\", image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64201ca9",
   "metadata": {},
   "source": [
    "<u>\n",
    "<h4>Configure tesseract path in implementations (No need to add in to the PATH explicitly)</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fa4ba38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# optional: only if you haven't configured PATH\n",
    "pt.pytesseract.tesseract_cmd = r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\" # provide full path to tesseract.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61caf321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "afr\n",
      "amh\n",
      "ara\n",
      "asm\n",
      "aze\n",
      "aze_cyrl\n",
      "bel\n",
      "ben\n",
      "bos\n",
      "bre\n",
      "bul\n",
      "cat\n",
      "ceb\n",
      "ces\n",
      "chi_sim\n",
      "chi_sim_vert\n",
      "chi_tra\n",
      "chi_tra_vert\n",
      "chr\n",
      "cos\n",
      "cym\n",
      "dan\n",
      "deu\n",
      "div\n",
      "dzo\n",
      "ell\n",
      "eng\n",
      "enm\n",
      "epo\n",
      "equ\n",
      "est\n",
      "eus\n",
      "fao\n",
      "fas\n",
      "fil\n",
      "fin\n",
      "fra\n",
      "frk\n",
      "frm\n",
      "fry\n",
      "gla\n",
      "gle\n",
      "glg\n",
      "grc\n",
      "guj\n",
      "hat\n",
      "heb\n",
      "hin\n",
      "hrv\n",
      "hun\n",
      "hye\n",
      "iku\n",
      "ind\n",
      "isl\n",
      "ita\n",
      "ita_old\n",
      "jav\n",
      "jpn\n",
      "jpn_vert\n",
      "kan\n",
      "kat\n",
      "kat_old\n",
      "kaz\n",
      "khm\n",
      "kir\n",
      "kmr\n",
      "kor\n",
      "lao\n",
      "lat\n",
      "lav\n",
      "lit\n",
      "ltz\n",
      "mal\n",
      "mar\n",
      "mkd\n",
      "mlt\n",
      "mon\n",
      "mri\n",
      "msa\n",
      "mya\n",
      "nep\n",
      "nld\n",
      "nor\n",
      "oci\n",
      "ori\n",
      "osd\n",
      "pan\n",
      "pol\n",
      "por\n",
      "pus\n",
      "que\n",
      "ron\n",
      "rus\n",
      "san\n",
      "sin\n",
      "slk\n",
      "slv\n",
      "snd\n",
      "spa\n",
      "spa_old\n",
      "sqi\n",
      "srp\n",
      "srp_latn\n",
      "sun\n",
      "swa\n",
      "swe\n",
      "syr\n",
      "tam\n",
      "tat\n",
      "tel\n",
      "tgk\n",
      "tha\n",
      "tir\n",
      "ton\n",
      "tur\n",
      "uig\n",
      "ukr\n",
      "urd\n",
      "uzb\n",
      "uzb_cyrl\n",
      "vie\n",
      "yid\n",
      "yor\n"
     ]
    }
   ],
   "source": [
    "# using cmd: tesseract --list-langs\n",
    "avb_langs = pt.get_languages(config='')\n",
    "\n",
    "for lang in avb_langs:\n",
    "    print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b8f663",
   "metadata": {},
   "source": [
    "<u>\n",
    "<h4>Extract text from an image : Simple</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0e6c8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 G08 gQdoucl maxHod Ognw, 68 qBonwe wo\n",
      "Smecnw an Was WAsdnst m Gumdmd\n",
      "BEd¢ ce Sdo Peau wang quo. CoOst © MO Hess\n",
      "g8s08 8ENe Go womBein wOnsl, edad Hoes on\n",
      "aE Hs eowOs acids On wBAcldao oOo! ©\n",
      "@@ cere gdalual edaomende ¢ BAO 08 F HO\n",
      "ae 8 @m qexhoh SedO e@an0e\n",
      "HWADOEO Ost © oder Héswck8 oO gQSOEO ¢\n",
      "wOAsld Bes oA ommdgqe, QAO ©O0 006 qhBad 8Q\n",
      "ead EMO OAR aD.\n",
      "\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m text \u001b[38;5;241m=\u001b[39m pt\u001b[38;5;241m.\u001b[39mimage_to_string(image)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(text)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36mshow_image\u001b[1;34m(img_path, size)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_image\u001b[39m(img_path, size\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m500\u001b[39m, \u001b[38;5;241m500\u001b[39m)):\n\u001b[0;32m      2\u001b[0m     image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(img_path)\n\u001b[1;32m----> 3\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMAGE\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m      6\u001b[0m     cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.7.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4062: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "image_path = test_image_files[22] # 2, 3, 12, 1, 13, 15\n",
    "path = create_path(image_path)\n",
    "\n",
    "image = Image.open(path)\n",
    "text = pt.image_to_string(image)\n",
    "\n",
    "print(text)\n",
    "show_image(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ad784b",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Extract text from an image : Specifying a language</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d067c55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = create_path(\"portu-text-2.jpg\")\n",
    "\n",
    "image = Image.open(path)\n",
    "text = pt.image_to_string(image, lang='por')\n",
    "\n",
    "print(text)\n",
    "show_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9984cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = create_path(\"WhatsApp Image 2023-01-13 at 11.12.39.jpg\")\n",
    "\n",
    "image = Image.open(path)\n",
    "text = pt.image_to_string(image, lang='por')\n",
    "\n",
    "print(text)\n",
    "show_image(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f082ed63",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Extract text from an image : Multiple images once</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd79b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name_txt_file = \"P:\\ML project\\project test images\\image-paths.txt\"\n",
    "text = pt.image_to_string(img_name_txt_file, lang='jpn')\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482cde39",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Extract text from an image : Timeout extraction</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ea3e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = create_path(\"news-2.jpg\")\n",
    "\n",
    "image = Image.open(path)\n",
    "text = 'NO TEXT TO BE APPEARED'\n",
    "\n",
    "try:\n",
    "    text = pt.image_to_string(image, lang='eng', timeout=5)\n",
    "except RuntimeError as timeout_error:\n",
    "    print(\"[TIMEOUT ERROR]\")\n",
    "\n",
    "print(text)\n",
    "show_image(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2d94ff",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Get bounding box estimates</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d00b69e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = create_path(\"jap-text-1.png\")\n",
    "\n",
    "image = Image.open(path)\n",
    "bound_rects = pt.image_to_boxes(image, lang='jpn')\n",
    "\n",
    "print(bound_rects)\n",
    "show_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62ca31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(path)\n",
    "h, _, _ = img.shape\n",
    "\n",
    "for b in bound_rects.splitlines():\n",
    "    b = b.strip().split(' ')\n",
    "    img = cv2.rectangle(img, (int(b[1]), h - int(b[2])), (int(b[3]), h - int(b[4])), (0, 255, 0), 2)\n",
    "\n",
    "cv2.imshow(\"CHARACTERIZED IMAGE\", img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594cfd83",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Get verbose data including boxes, confidences, line and page numbers</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da99c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = test_image_files[2]\n",
    "path = create_path(image_path)\n",
    "\n",
    "image = Image.open(path)\n",
    "text = pt.image_to_data(image)\n",
    "\n",
    "print(text)\n",
    "show_image(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d1f74a",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Get information about orientation and script detection</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9952ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"hindi-text-1.jpg\" # news-2.jpg hindi-news-1.jpg hindi-news-2.jpg hindi-text-1.jpg\n",
    "path = create_path(image_path)\n",
    "\n",
    "print(pt.image_to_osd(path, lang='hin'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7077208b",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Convert in to different file formats (PDF, XML, HOCR)</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b0116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"news-2.jpg\"\n",
    "path = create_path(image_path)\n",
    "file_save_path = r\"P:\\ML project\\files\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e8f68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf = pt.image_to_pdf_or_hocr(path, extension='pdf')\n",
    "\n",
    "file = open(os.path.join(file_save_path, \"pdf-content1.pdf\"), 'w+b')\n",
    "file.write(pdf)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f7d502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hocr: open standard of data representation for formatted text obtained from (OCR)\n",
    "hocr = pt.image_to_pdf_or_hocr(path, extension='hocr')\n",
    "\n",
    "file = open(os.path.join(file_save_path, \"hocr-content.html\"), 'w+b')\n",
    "file.write(hocr)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e165752",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml = pt.image_to_alto_xml(path)\n",
    "\n",
    "file = open(os.path.join(file_save_path, \"xml-content.xml\"), 'w+b')\n",
    "file.write(xml)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2ebff7",
   "metadata": {},
   "source": [
    "<u>\n",
    "    <h4>Forcefully assigning different assumptions (Custom Configurations)</h4>\n",
    "</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fa3458",
   "metadata": {},
   "source": [
    "<b>OEM</b> : OCR Engine Mode (Type of the algorithm used by tesseract)<br>\n",
    "<b>PEM</b> : Page Segmentation Mode (Page semgentation mode used by tesseract)<br><br>\n",
    " \n",
    "<h4>Page Segmentation Modes</h4><hr>\n",
    "<div style=\"font-size:13px;\">\n",
    "\n",
    "    \n",
    "0 - Orientation and script detection(OSD) only.<br>\n",
    "1 - Automatic page segmentation with OSD.<br>\n",
    "2 - Automatic page segmentation, but no OSD, or OCR.<br>\n",
    "3 - Fully automatic page segmentation, but no OSD.(Default)<br>\n",
    "4 - Assume a single column of text of variable sizes.<br>\n",
    "5 - Assume a single uniform block of vertically aligned text.<br>\n",
    "6 - Assume a single uniform block of text.<br>\n",
    "7 - Treat the image as a single text line.<br>\n",
    "8 - Treat the image as a single word.<br>\n",
    "9 - Treat the image as a single word in a circle.<br>\n",
    "10 - Treat the image as a single character.<br>\n",
    "11 - Sparse text.Find as much text as possible in no particular order.<br>\n",
    "12 - Sparse text with OSD.<br>\n",
    "13 - Raw line.Treat the image as a single text line, bypassing hacks that are Tesseract - specific.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302d4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"abc-text.jpg\"\n",
    "path = create_path(image_path)\n",
    "custom_oem_psm_config = r'--oem 3 --psm 9'\n",
    "\n",
    "image = Image.open(path)\n",
    "pt.image_to_string(image, config=custom_oem_psm_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1702e3",
   "metadata": {},
   "source": [
    "<h4>References</h4><hr>\n",
    "\n",
    "<ul>\n",
    "    <li><a href='https://github.com/tesseract-ocr/tesseract'>Tesseract</a></li>\n",
    "    <li><a href='https://github.com/madmaze/pytesseract'>Pytesseract</a></li>\n",
    "    <li><a href='https://www.py4u.net/discuss/10850'>Multiple config options</a></li>\n",
    "    <li><a href='https://stackoverflow.com/questions/20831612/getting-the-bounding-box-of-the-recognized-words-using-python-tesseract'>Getting bounding box cordinates</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515e3a30",
   "metadata": {},
   "source": [
    "# Project by \n",
    "### * Aaditya Kumar \n",
    " \n",
    "### * Bittu Kumar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "8cbd1a1ee4828adf97587f39a9e163376829944349df26b6897c312e7bb2ead2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
